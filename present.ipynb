{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from mod.logs import Logger\n",
    "from mod.dao import MyConn, SqlStatement\n",
    "from data_lake import PT_TABLE, OP_TABLE, DX_TABLE\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare modules\n",
    "l = Logger()\n",
    "conn = MyConn(\"127.0.0.1\", \"hecon\", l, False)\n",
    "builder = SqlStatement()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "        select * from hecon.pt_dl\n",
      "        \n",
      "\n",
      "        select * from hecon.op_dl\n",
      "        \n",
      "\n",
      "        select * from hecon.dx_dl\n",
      "        \n"
     ]
    }
   ],
   "source": [
    "# Load data from database\n",
    "pt = conn.wrap(builder.read_data, table=PT_TABLE)\n",
    "op = conn.wrap(builder.read_data, table=OP_TABLE)\n",
    "dx = conn.wrap(builder.read_data, table=DX_TABLE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PT data: Before (243, 16) / After Duplicate Removal (243, 16)\n",
      "OP data: Before (243, 43) / After Duplicate Removal (243, 43)\n",
      "DX data: Before (243, 46) / After Duplicate Removal (243, 46)\n"
     ]
    }
   ],
   "source": [
    "# Remove duplicates?\n",
    "# Let's write a simple duplicate removal code. \n",
    "\n",
    "def remove_duplicates(data: np.ndarray, pivot_order=None) -> pd.DataFrame:\n",
    "    if pivot_order is None:\n",
    "        pivot_order = {\"index\": 1, \"columns\": 0, \"values\": 2}\n",
    "\n",
    "    # Create data\n",
    "    df = pd.DataFrame(data)\n",
    "    df_pivot = df.pivot(**pivot_order)\n",
    "\n",
    "    # Identify duplicate rows, where the current row is the same as the previous row\n",
    "    df_pivot[\"is_dup\"] = df_pivot.duplicated(\n",
    "        subset=df_pivot.columns.difference([\"dates\"]),\n",
    "        keep=\"first\",\n",
    "    ) & ~df_pivot.duplicated(\n",
    "        subset=df_pivot.columns.difference([\"dates\"]),\n",
    "        keep=\"last\",\n",
    "    )\n",
    "\n",
    "    # Keep only the rows that are not marked as duplicates\n",
    "    df_cleaned = df_pivot[\n",
    "        ~df_pivot[\"is_dup\"] |\n",
    "        df_pivot.duplicated(\n",
    "            subset=df_pivot.columns.difference([\"dates\"]),\n",
    "            keep=\"last\"\n",
    "        )\n",
    "        ].drop(columns=\"is_dup\")\n",
    "    df_cleaned.reset_index(drop=True, inplace=True)\n",
    "    return df_pivot\n",
    "\n",
    "\n",
    "# PT Data\n",
    "pt_original = pd.DataFrame(pt)\n",
    "pt_original = pt_original.pivot(index=1, columns=0, values=2).reset_index()\n",
    "pt_remove_dup = remove_duplicates(pt)\n",
    "print(\n",
    "    f\"PT data: Before {pt_original.shape} / After Duplicate Removal {pt_remove_dup.shape}\"\n",
    ")\n",
    "\n",
    "# OP Data\n",
    "op_original = pd.DataFrame(op)\n",
    "op_original = op_original.pivot(index=1, columns=0, values=2).reset_index()\n",
    "op_remove_dup = remove_duplicates(op)\n",
    "print(\n",
    "    f\"OP data: Before {op_original.shape} / After Duplicate Removal {op_remove_dup.shape}\"\n",
    ")\n",
    "\n",
    "# DX Data\n",
    "dx_original = pd.DataFrame(dx)\n",
    "dx_original = dx_original.pivot(index=1, columns=0, values=2).reset_index()\n",
    "dx_remove_dup = remove_duplicates(dx)\n",
    "print(\n",
    "    f\"DX data: Before {dx_original.shape} / After Duplicate Removal {dx_remove_dup.shape}\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Regarding Duplication Removal?\n",
    "\n",
    "```python\n",
    "PT data: Before (243, 16) / After Duplicate Removal (243, 16)\n",
    "OP data: Before (243, 43) / After Duplicate Removal (243, 43)\n",
    "DX data: Before (243, 46) / After Duplicate Removal (243, 46)\n",
    "```\n",
    "\n",
    "<h3><i>No datapoints were removed</i></h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Regarding Zero Inflation ?\n",
    "|\t| 0개수 | 전체 개수 | 0 비율 | 연구자 자료 |\n",
    "|---|------|--------|----|-----------|\n",
    "|OP | 7095 | 10206 | 0.6952 | 약 70% |\n",
    "|DX | 7467 | 10935 | 0.682853224 | 약 69% |\n",
    "\n",
    "* 90% 넘는 물품만 제거한다고 하였기 때문에, 70% 인 물품 제거 안함. \n",
    "* 이미 시점 개수가 243개인 것을 보아, 이미 정리된 자료를 준 것으로 추정됨."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hecon23",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
